# -*- coding: utf-8 -*-
"""scrapping1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IYFK-om7b_YUqfch_nE67CVQSzZ1r8hk
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

Base_url = "https://books.toscrape.com/"
titles= []
prices=[]
availabilities = []
ratings = []

for page in range(1,51):
  url=Base_url.format(page)
  response=requests.get(url)
  soup=BeautifulSoup(response.text,"html.parser")
  books=soup.find_all("article",class_="product_pod")
  for book in books:
    title=book.h3.a["title"]
    titles.append(title)
    price=book.find("p",class_="price_color").text
    prices.append(price)
    availability=book.find("p",class_="instock availability").text.strip()
    availabilities.append(availability)
    rating=book.find("p",class_="star-rating")["class"][1]
    ratings.append(rating)
print("data scrapped sucessfully!")
df = pd.DataFrame({
    "Title": titles,
    "Price": prices,
    "Availability": availabilities,
    "Star Rating": ratings
})
df.to_csv("books.csv", index=False)
print("data saved to books.csv")

!pip install selenium pandas webdriver-manager

!apt-get update
!apt-get install -y google-chrome-stable

import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

options = webdriver.ChromeOptions()
options.add_argument("--headless")  # Run in background, remove this line if you want to see the browser
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.binary_location = "/usr/bin/google-chrome"

driver = webdriver.Chrome(
    service=Service(ChromeDriverManager().install()),
    options=options
)